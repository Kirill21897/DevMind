# Фаза 7: Observability и Трейсинг с LangFuse

## Обзор
Для улучшения качества работы агента и отладки сложных запросов нам необходимо видеть, что происходит "под капотом". **LangFuse** — это open-source платформа для LLM observability. Она позволяет трекать каждый вызов к LLM, время выполнения, стоимость (токены) и качество ответов.

## Выбор технологий
*   **LangFuse**: SDK для Python.
    *   *Преимущества*: Подробные трейсы (Traces), поддержка оценки (Scores), управление промптами, удобный дэшборд.

## План реализации

### 1. Установка и Конфигурация
*   Добавить `langfuse` в `requirements.txt`.
*   Настроить переменные окружения в `.env`:
    ```ini
    LANGFUSE_SECRET_KEY=sk-lf-...
    LANGFUSE_PUBLIC_KEY=pk-lf-...
    LANGFUSE_HOST=https://cloud.langfuse.com (или локальный хост)
    ```

### 2. Интеграция в код (`src/agent.py`)
Мы будем использовать декоратор `@observe()` или обертку для OpenAI клиента.
Так как мы используем стандартный клиент `openai`, интеграция будет простой:
*   Обернуть клиент: `from langfuse.openai import OpenAI as LangfuseOpenAI`.
*   Это автоматически отправит все вызовы LLM в LangFuse.
*   Добавить декоратор `@observe()` к методу `run` агента, чтобы группировать шаги (мысли, вызовы инструментов) в один Trace.

### 3. Трекинг инструментов
*   Обернуть методы инструментов (`retrieve_knowledge`, `web_search`) в декоратор `@observe(as_type="generation")` или использовать `langfuse_context` для создания спанов (spans). Это позволит видеть, сколько времени занял каждый инструмент и что он вернул.

### 4. Оценка (Scores)
*   Добавить возможность программно отправлять оценку (feedback) после ответа. В будущем это можно подключить к кнопкам "лайк/дизлайк" в Chainlit UI.

## Ожидаемый результат
После каждого диалога в LangFuse Dashboard появляется новый Trace, показывающий:
1.  Входящий запрос пользователя.
2.  Цепочку вызовов (ReAct Loop).
3.  Входные и выходные данные каждого инструмента.
4.  Итоговый ответ и токенотраты.
